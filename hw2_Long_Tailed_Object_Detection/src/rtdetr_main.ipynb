{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 基礎設定"
      ],
      "metadata": {
        "id": "tbWyrGTDVhCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK7Qpc_9X1xq",
        "outputId": "b4d59d1d-37fa-4e76-b505-162e49090ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json, math, shutil, zipfile, random, time, csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import yaml"
      ],
      "metadata": {
        "id": "2vMOfd3eX14_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.backends.cudnn.benchmark = True  # 加速"
      ],
      "metadata": {
        "id": "lZddECfAX17S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 關 W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "PuZuJgBTX19j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "69Xr1vHdX1__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_PATH = \"/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/taica-cvpdl-2025-hw-2.zip\"\n",
        "EXTRACT_DIR = \"/content/data_hw2\"\n",
        "REPORT_DIR  = \"/content/reports\"\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "\n",
        "# 提交輸出\n",
        "SUBMIT_DIR = \"/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/submissions\"\n",
        "os.makedirs(SUBMIT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "i-IpeplPZ925"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 解壓 & 掃描資料"
      ],
      "metadata": {
        "id": "RNV3yTDIaBoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_dataset_root(root):\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        if 'train' in dirnames and 'test' in dirnames:\n",
        "            return dirpath\n",
        "    candidate_trains = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        if os.path.basename(dirpath).lower() == 'train':\n",
        "            has_txt = any(fn.lower().endswith('.txt') for fn in filenames)\n",
        "            has_png = any(fn.lower().endswith('.png') for fn in filenames)\n",
        "            if has_txt and has_png:\n",
        "                candidate_trains.append(dirpath)\n",
        "    candidate_trains = sorted(candidate_trains, key=lambda d: len(d.split(os.sep)), reverse=True)\n",
        "    for tdir in candidate_trains:\n",
        "        parent = os.path.dirname(tdir)\n",
        "        tdir_sibling_test = os.path.join(parent, 'test')\n",
        "        if os.path.isdir(tdir_sibling_test):\n",
        "            return parent\n",
        "    return None"
      ],
      "metadata": {
        "id": "i-8Wac-jZ-fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
        "    zf.extractall(EXTRACT_DIR)"
      ],
      "metadata": {
        "id": "GPBvTWZadWQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = find_dataset_root(EXTRACT_DIR)\n",
        "if DATASET_ROOT is None:\n",
        "    raise RuntimeError(f\"找不到包含 train/test 的資料夾，請檢查 {EXTRACT_DIR} 的解壓內容結構\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(DATASET_ROOT, 'train')\n",
        "TEST_DIR  = os.path.join(DATASET_ROOT, 'test')"
      ],
      "metadata": {
        "id": "1bfejTBwdWTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sorted_by_stem(paths):\n",
        "    return sorted(paths, key=lambda p: os.path.splitext(os.path.basename(p))[0])\n",
        "\n",
        "TRAIN_IMGS = sorted_by_stem(glob.glob(os.path.join(TRAIN_DIR, \"*.png\")))\n",
        "TRAIN_TXTS = sorted_by_stem(glob.glob(os.path.join(TRAIN_DIR, \"*.txt\")))\n",
        "TEST_IMGS  = sorted_by_stem(glob.glob(os.path.join(TEST_DIR,  \"*.png\")))\n"
      ],
      "metadata": {
        "id": "Sq1de6MCdWVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(p): return os.path.splitext(os.path.basename(p))[0]\n",
        "train_img_by_stem = {stem(p): p for p in TRAIN_IMGS}\n",
        "train_lab_by_stem = {stem(p): p for p in TRAIN_TXTS}"
      ],
      "metadata": {
        "id": "EOIbcS2ndWX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMMON_KEYS = sorted(set(train_img_by_stem) & set(train_lab_by_stem))\n",
        "ONLY_IMG    = sorted(set(train_img_by_stem) - set(train_lab_by_stem))\n",
        "ONLY_TXT    = sorted(set(train_lab_by_stem) - set(train_img_by_stem))\n",
        "\n",
        "print(f\"DATASET_ROOT: {DATASET_ROOT}\")\n",
        "print(f\"TRAIN_DIR   : {TRAIN_DIR}\")\n",
        "print(f\"TEST_DIR    : {TEST_DIR}\")\n",
        "print(f\"Train images: {len(TRAIN_IMGS)} | Train labels: {len(TRAIN_TXTS)} | Test images: {len(TEST_IMGS)}\")\n",
        "print(f\"Paired train files: {len(COMMON_KEYS)} | only_img: {len(ONLY_IMG)} | only_txt: {len(ONLY_TXT)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCCvPALAdWaH",
        "outputId": "c3a012ed-54c2-4908-9b22-09d87c78a2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET_ROOT: /content/data_hw2/CVPDL_hw2/CVPDL_hw2\n",
            "TRAIN_DIR   : /content/data_hw2/CVPDL_hw2/CVPDL_hw2/train\n",
            "TEST_DIR    : /content/data_hw2/CVPDL_hw2/CVPDL_hw2/test\n",
            "Train images: 950 | Train labels: 950 | Test images: 550\n",
            "Paired train files: 950 | only_img: 0 | only_txt: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2) 基礎工具 & 清理規則\n",
        "# ========================="
      ],
      "metadata": {
        "id": "AbPCULJzdWcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = [\"car\", \"hov\", \"person\", \"motorcycle\"]"
      ],
      "metadata": {
        "id": "7GlbCBlDdWe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BBox:\n",
        "    cls: int; x: int; y: int; w: int; h: int\n",
        "\n",
        "def imread_rgb(p):\n",
        "    im = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "    if im is None: return None\n",
        "    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def parse_label_line(line):\n",
        "    parts = [x.strip() for x in line.split(\",\")]\n",
        "    if len(parts) != 5:\n",
        "        return None\n",
        "    try:\n",
        "        c, x, y, w, h = map(int, parts)\n",
        "        return BBox(c, x, y, w, h)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_label_txt(txt_path):\n",
        "    items, bad_lines = [], []\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for ln, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            bb = parse_label_line(line)\n",
        "            if bb is None:\n",
        "                bad_lines.append((ln, line))\n",
        "            else:\n",
        "                items.append(bb)\n",
        "    return items, bad_lines\n",
        "\n",
        "DIM_CACHE = {}\n",
        "def get_hw(img_path):\n",
        "    if img_path in DIM_CACHE:\n",
        "        return DIM_CACHE[img_path]\n",
        "    im = imread_rgb(img_path)\n",
        "    if im is None:\n",
        "        return None\n",
        "    h, w = im.shape[:2]\n",
        "    DIM_CACHE[img_path] = (h, w)\n",
        "    return h, w\n",
        "\n",
        "def iou_xywh(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a.x, a.y, a.x + a.w, a.y + a.h\n",
        "    bx1, by1, bx2, by2 = b.x, b.y, b.x + b.w, b.y + b.h\n",
        "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
        "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)\n",
        "    inter = iw * ih\n",
        "    if inter <= 0: return 0.0\n",
        "    a_area = a.w * a.h\n",
        "    b_area = b.w * b.h\n",
        "    union = a_area + b_area - inter + 1e-6\n",
        "    return inter / union\n",
        "\n",
        "def clip_bbox(bb, W, H):\n",
        "    x1 = max(0, min(bb.x, W-1))\n",
        "    y1 = max(0, min(bb.y, H-1))\n",
        "    x2 = max(0, min(bb.x + bb.w, W))\n",
        "    y2 = max(0, min(bb.y + bb.h, H))\n",
        "    w = max(0, x2 - x1)\n",
        "    h = max(0, y2 - y1)\n",
        "    return BBox(bb.cls, x1, y1, w, h)\n"
      ],
      "metadata": {
        "id": "a6YUgXZiddpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_SIDE_PX = 2\n",
        "MIN_AREA_PX = 4\n",
        "VALID_CLASS_IDS = set(range(len(CLASSES)))\n",
        "DUP_IOU_THR = 0.9"
      ],
      "metadata": {
        "id": "sQ0pbvr5ddr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dedup_by_iou(items, thr=0.9):\n",
        "    kept = []\n",
        "    items_sorted = sorted(items, key=lambda b: b.w*b.h, reverse=True)\n",
        "    for bb in items_sorted:\n",
        "        drop = False\n",
        "        for kk in kept:\n",
        "            if bb.cls == kk.cls and iou_xywh(bb, kk) > thr:\n",
        "                drop = True; break\n",
        "        if not drop:\n",
        "            kept.append(bb)\n",
        "    return kept\n"
      ],
      "metadata": {
        "id": "0qJ5xvBFdduS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3) 報表與清理到 labels_clean（路徑統一）\n",
        "# ========================="
      ],
      "metadata": {
        "id": "qPFxrASrddww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_rows = []; invalid_cls = []; nonpos_wh = []; oob_boxes = []; tiny_boxes = []; dup_boxes = []\n",
        "per_image_class_count = defaultdict(lambda: Counter())\n",
        "size_buckets = Counter()"
      ],
      "metadata": {
        "id": "fVU4WxSBddzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bucket_by_area_ratio(w, h, W, H):\n",
        "    ratio = (w*h) / float(W*H + 1e-6)\n",
        "    if ratio < 0.001: return \"small\"\n",
        "    elif ratio < 0.01: return \"medium\"\n",
        "    else: return \"large\"\n",
        "\n",
        "for k in COMMON_KEYS:\n",
        "    img_p, txt_p = train_img_by_stem[k], train_lab_by_stem[k]\n",
        "    dim = get_hw(img_p)\n",
        "    if dim is None:\n",
        "        bad_rows.append([k, \"image_read_fail\", \"\", \"\"]); continue\n",
        "    H,W = dim\n",
        "    items, bads = load_label_txt(txt_p)\n",
        "    for (ln, line) in bads:\n",
        "        bad_rows.append([k, \"parse_fail\", ln, line])\n",
        "    for it in items:\n",
        "        per_image_class_count[k][it.cls] += 1\n",
        "        if it.cls not in VALID_CLASS_IDS:\n",
        "            invalid_cls.append([k, it.cls])\n",
        "        if it.w <= 0 or it.h <= 0:\n",
        "            nonpos_wh.append([k, it.cls, it.x, it.y, it.w, it.h])\n",
        "        if not (0 <= it.x < W and 0 <= it.y < H and it.x + it.w <= W + 1 and it.y + it.h <= H + 1):\n",
        "            oob_boxes.append([k, it.cls, it.x, it.y, it.w, it.h, W, H])\n",
        "        if it.w < MIN_SIDE_PX or it.h < MIN_SIDE_PX or (it.w * it.h) < MIN_AREA_PX:\n",
        "            tiny_boxes.append([k, it.cls, it.x, it.y, it.w, it.h])\n",
        "        else:\n",
        "            size_buckets[bucket_by_area_ratio(it.w, it.h, W, H)] += 1\n",
        "    for c in set([it.cls for it in items]):\n",
        "        cls_items = [it for it in items if it.cls == c and it.w > 0 and it.h > 0]\n",
        "        n = len(cls_items)\n",
        "        for i in range(n):\n",
        "            for j in range(i+1, n):\n",
        "                if iou_xywh(cls_items[i], cls_items[j]) > DUP_IOU_THR:\n",
        "                    dup_boxes.append([k, c, i, j])\n",
        "\n",
        "def write_csv(path, header, rows):\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f); w.writerow(header); w.writerows(rows)\n"
      ],
      "metadata": {
        "id": "F3XCmVbxdd04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_csv(os.path.join(REPORT_DIR, \"bad_rows.csv\"), [\"stem\",\"reason\",\"line_no\",\"raw_line\"], bad_rows)\n",
        "write_csv(os.path.join(REPORT_DIR, \"invalid_class.csv\"), [\"stem\",\"cls\"], invalid_cls)\n",
        "write_csv(os.path.join(REPORT_DIR, \"nonpos_wh.csv\"), [\"stem\",\"cls\",\"x\",\"y\",\"w\",\"h\"], nonpos_wh)\n",
        "write_csv(os.path.join(REPORT_DIR, \"out_of_bounds.csv\"), [\"stem\",\"cls\",\"x\",\"y\",\"w\",\"h\",\"W\",\"H\"], oob_boxes)\n",
        "write_csv(os.path.join(REPORT_DIR, \"tiny_boxes.csv\"), [\"stem\",\"cls\",\"x\",\"y\",\"w\",\"h\"], tiny_boxes)\n",
        "write_csv(os.path.join(REPORT_DIR, \"duplicate_boxes.csv\"), [\"stem\",\"cls\",\"idx_i\",\"idx_j\"], dup_boxes)\n"
      ],
      "metadata": {
        "id": "y5rFPrJKdk8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = Counter()\n",
        "for k, cnt in per_image_class_count.items():\n",
        "    for c, v in cnt.items():\n",
        "        class_counts[c] += v\n",
        "\n",
        "stats = {\n",
        "    \"class_counts\": {CLASSES[c]: int(class_counts[c]) for c in range(len(CLASSES))},\n",
        "    \"size_buckets\": dict(size_buckets),\n",
        "    \"num_train_pairs\": len(COMMON_KEYS),\n",
        "    \"only_img\": len(ONLY_IMG),\n",
        "    \"only_txt\": len(ONLY_TXT),\n",
        "}\n",
        "with open(os.path.join(REPORT_DIR, \"dataset_stats.json\"), \"w\") as f:\n",
        "    json.dump(stats, f, indent=2)\n",
        "print(json.dumps(stats, indent=2))\n",
        "print(f\"Reports saved under: {REPORT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_SvHy83doBO",
        "outputId": "e1e6d452-18b2-4e60-89dd-686333557d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"class_counts\": {\n",
            "    \"car\": 23275,\n",
            "    \"hov\": 1345,\n",
            "    \"person\": 3363,\n",
            "    \"motorcycle\": 5348\n",
            "  },\n",
            "  \"size_buckets\": {\n",
            "    \"small\": 23201,\n",
            "    \"medium\": 9891,\n",
            "    \"large\": 239\n",
            "  },\n",
            "  \"num_train_pairs\": 950,\n",
            "  \"only_img\": 0,\n",
            "  \"only_txt\": 0\n",
            "}\n",
            "Reports saved under: /content/reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 清理到 DATASET_ROOT/labels_clean（路徑統一）\n",
        "CLEAN_LAB_DIR = os.path.join(DATASET_ROOT, \"labels_clean\")\n",
        "os.makedirs(CLEAN_LAB_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "gbCDG1L4dptK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_changed = 0\n",
        "for k in COMMON_KEYS:\n",
        "    img_p, txt_p = train_img_by_stem[k], train_lab_by_stem[k]\n",
        "    dim = get_hw(img_p)\n",
        "    if dim is None: continue\n",
        "    H, W = dim\n",
        "    items, _ = load_label_txt(txt_p)\n",
        "    fixed = []\n",
        "    for it in items:\n",
        "        it2 = clip_bbox(it, W, H)\n",
        "        if it2.w <= 0 or it2.h <= 0: continue\n",
        "        if it2.w < MIN_SIDE_PX or it2.h < MIN_SIDE_PX: continue\n",
        "        fixed.append(it2)\n",
        "    fixed2 = dedup_by_iou(fixed, thr=DUP_IOU_THR)\n",
        "    out_p = os.path.join(CLEAN_LAB_DIR, f\"{k}.txt\")\n",
        "    with open(out_p, \"w\") as f:\n",
        "        for b in fixed2:\n",
        "            f.write(f\"{b.cls},{b.x},{b.y},{b.w},{b.h}\\n\")\n",
        "    if len(fixed2) != len(items): num_changed += 1\n",
        "\n",
        "print(f\"Cleaned labels saved under: {CLEAN_LAB_DIR} | files_changed: {num_changed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Z4uAAGdrus",
        "outputId": "9dd766e3-d3cc-4525-e06e-19087838281a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned labels saved under: /content/data_hw2/CVPDL_hw2/CVPDL_hw2/labels_clean | files_changed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 轉 YOLO 標註格式（cx cy w h, 0~1）"
      ],
      "metadata": {
        "id": "fCdWpxk6dta8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_LAB_DIR = CLEAN_LAB_DIR if len(glob.glob(os.path.join(CLEAN_LAB_DIR, \"*.txt\"))) > 0 else TRAIN_DIR\n",
        "print(\"Using labels from:\", USE_LAB_DIR, \"files=\", len(glob.glob(os.path.join(USE_LAB_DIR, \"*.txt\"))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpxna22Ndu05",
        "outputId": "e2d2b9b1-4e6a-4ebe-fdf8-a392aab959d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using labels from: /content/data_hw2/CVPDL_hw2/CVPDL_hw2/labels_clean files= 950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO_ROOT = \"/content/yolo_dataset\"\n",
        "IMG_DIR   = os.path.join(YOLO_ROOT, \"images\")\n",
        "LAB_DIR   = os.path.join(YOLO_ROOT, \"labels\")\n",
        "shutil.rmtree(YOLO_ROOT, ignore_errors=True)\n",
        "os.makedirs(IMG_DIR, exist_ok=True); os.makedirs(LAB_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "rAxh29ltdu3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_DIM_CACHE = {}\n",
        "def get_hw_fast(img_path):\n",
        "    if img_path in _DIM_CACHE: return _DIM_CACHE[img_path]\n",
        "    im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    if im is None: return None\n",
        "    h, w = im.shape[:2]\n",
        "    _DIM_CACHE[img_path] = (h, w)\n",
        "    return h, w\n",
        "\n",
        "def load_items_txt(txt_path):\n",
        "    items = []\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            if not line: continue\n",
        "            parts=[x.strip() for x in line.split(\",\")]\n",
        "            if len(parts)!=5: continue\n",
        "            c,x,y,w,h = map(int, parts)\n",
        "            items.append((c,x,y,w,h))\n",
        "    return items\n",
        "\n",
        "num_ok, num_skip = 0, 0\n",
        "for k in tqdm(COMMON_KEYS, desc=\"Convert to YOLO labels\"):\n",
        "    src_img = train_img_by_stem[k]\n",
        "    src_lab = os.path.join(USE_LAB_DIR, f\"{k}.txt\")\n",
        "    if not os.path.isfile(src_img) or not os.path.isfile(src_lab):\n",
        "        num_skip += 1; continue\n",
        "    hw = get_hw_fast(src_img)\n",
        "    if hw is None: num_skip += 1; continue\n",
        "    H, W = hw\n",
        "    dst_img = os.path.join(IMG_DIR, f\"{k}.png\")\n",
        "    if not os.path.isfile(dst_img):\n",
        "        shutil.copy2(src_img, dst_img)\n",
        "    items = load_items_txt(src_lab)\n",
        "    yolo_lines = []\n",
        "    for (c,x,y,w,h) in items:\n",
        "        if w <= 0 or h <= 0: continue\n",
        "        cx, cy = x + w/2, y + h/2\n",
        "        yolo_cx = min(1, max(0, cx / W))\n",
        "        yolo_cy = min(1, max(0, cy / H))\n",
        "        yolo_w  = min(1, max(0, w / W))\n",
        "        yolo_h  = min(1, max(0, h / H))\n",
        "        yolo_lines.append(f\"{c} {yolo_cx:.6f} {yolo_cy:.6f} {yolo_w:.6f} {yolo_h:.6f}\")\n",
        "    with open(os.path.join(LAB_DIR, f\"{k}.txt\"), \"w\") as f:\n",
        "        f.write(\"\\n\".join(yolo_lines))\n",
        "    num_ok += 1\n",
        "\n",
        "print(f\"Converted: {num_ok} | Skipped: {num_skip}\")\n",
        "print(\"YOLO dataset root:\", YOLO_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY54_daVdu5j",
        "outputId": "b17622e6-2cfd-4155-aa2d-b999d4d0357e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Convert to YOLO labels: 100%|██████████| 950/950 [00:51<00:00, 18.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted: 950 | Skipped: 0\n",
            "YOLO dataset root: /content/yolo_dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5) 5 折（多標籤分層）＋ Head-only 下採樣 ＋ RFS\n",
        "# ========================="
      ],
      "metadata": {
        "id": "o1Pk8L-udu73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install scikit-multilearn==0.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y229M3FNd0IE",
        "outputId": "f737f491-4258-43fd-c7a3-a782355a7e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "metadata": {
        "id": "dtErtmJKd0Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "presence_vector = {}\n",
        "cls_counts_per_img = {}\n",
        "for k in COMMON_KEYS:\n",
        "    lab_p = os.path.join(LAB_DIR, f\"{k}.txt\")\n",
        "    cnt = Counter(); vec = [0]*len(CLASSES)\n",
        "    if os.path.isfile(lab_p):\n",
        "        with open(lab_p, \"r\") as f:\n",
        "            for line in f:\n",
        "                line=line.strip()\n",
        "                if not line: continue\n",
        "                cid=int(line.split()[0])\n",
        "                cnt[cid]+=1; vec[cid]=1\n",
        "    cls_counts_per_img[k]=cnt; presence_vector[k]=vec\n",
        "\n",
        "X = list(COMMON_KEYS)\n",
        "Y = np.array([presence_vector[k] for k in X], dtype=int)\n",
        "mskf = IterativeStratification(n_splits=5, order=1)\n",
        "folds=[]\n",
        "for tr_idx, va_idx in mskf.split(X, Y):\n",
        "    tr_keys = [X[i] for i in tr_idx]\n",
        "    va_keys = [X[i] for i in va_idx]\n",
        "    folds.append({\"train\": tr_keys, \"val\": va_keys})\n",
        "with open(os.path.join(REPORT_DIR, \"folds_5.json\"), \"w\") as f:\n",
        "    json.dump(folds, f, indent=2)\n",
        "print(\"Saved 5 multilabel folds ->\", os.path.join(REPORT_DIR, \"folds_5.json\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP95GY0hd0M3",
        "outputId": "105eece2-b1de-497d-cd0f-bd7bd786b25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 5 multilabel folds -> /content/reports/folds_5.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Head-only 下採樣（僅含 car 的影像）\n",
        "HEAD_ONLY = [k for k,v in presence_vector.items() if v[0]==1 and sum(v[1:])==0]\n",
        "HEAD_KEEP = 0.5\n",
        "\n",
        "def downsample_head_only(keys):\n",
        "    heads = [k for k in keys if k in HEAD_ONLY]\n",
        "    others= [k for k in keys if k not in HEAD_ONLY]\n",
        "    keep_n = int(len(heads) * HEAD_KEEP)\n",
        "    kept_head = random.sample(heads, keep_n) if keep_n < len(heads) else heads\n",
        "    return others + kept_head\n",
        "\n",
        "for f in folds:\n",
        "    f[\"train\"] = downsample_head_only(f[\"train\"])\n"
      ],
      "metadata": {
        "id": "w6-bnwxTd0PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RFS\n",
        "global_cls_counts = Counter()\n",
        "for k in COMMON_KEYS:\n",
        "    global_cls_counts.update(cls_counts_per_img[k])\n",
        "eps=1e-9\n",
        "total_boxes = sum(global_cls_counts.values()) + eps\n",
        "freq = {c:(global_cls_counts[c]/total_boxes) for c in range(len(CLASSES))}\n",
        "repeat_thresh_per_class = {1:0.006, 2:0.010, 3:0.008}  # hov/person/motorcycle\n",
        "BASE_T = 0.002\n",
        "RFS_CAP = 3.0\n",
        "\n",
        "def image_repeat_factor(k):\n",
        "    max_r = 1.0\n",
        "    for c, n in cls_counts_per_img[k].items():\n",
        "        t = repeat_thresh_per_class.get(c, BASE_T)\n",
        "        fc = freq.get(c, 1e-9)\n",
        "        r = math.sqrt(t / max(fc, 1e-9))\n",
        "        max_r = max(max_r, r)\n",
        "    return min(max_r, RFS_CAP)\n",
        "\n",
        "LIST_DIR = os.path.join(YOLO_ROOT, \"splits\")\n",
        "os.makedirs(LIST_DIR, exist_ok=True)\n",
        "\n",
        "def img_path_of(k): return os.path.join(IMG_DIR, f\"{k}.png\")\n",
        "\n",
        "for fi, fold in enumerate(folds):\n",
        "    tr, va = fold[\"train\"], fold[\"val\"]\n",
        "    with open(os.path.join(LIST_DIR, f\"fold{fi}_train.txt\"), \"w\") as f:\n",
        "        for k in tr: f.write(img_path_of(k) + \"\\n\")\n",
        "    with open(os.path.join(LIST_DIR, f\"fold{fi}_val.txt\"), \"w\") as f:\n",
        "        for k in va: f.write(img_path_of(k) + \"\\n\")\n",
        "    with open(os.path.join(LIST_DIR, f\"fold{fi}_train_rfs.txt\"), \"w\") as f:\n",
        "        for k in tr:\n",
        "            n_rep = int(round(image_repeat_factor(k)))\n",
        "            for _ in range(max(1, n_rep)): f.write(img_path_of(k) + \"\\n\")\n",
        "\n",
        "print(\"Generated split lists under:\", LIST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvwwM48ud0Rh",
        "outputId": "4fd045e7-1779-4ceb-a9d2-7a6893898985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated split lists under: /content/yolo_dataset/splits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6) Per-fold AUG（Tail Copy-Paste）\n",
        "# ========================="
      ],
      "metadata": {
        "id": "vZKIpAnKd0T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUG_ROOT = \"/content/yolo_dataset_aug\"\n",
        "shutil.rmtree(AUG_ROOT, ignore_errors=True)\n",
        "os.makedirs(AUG_ROOT, exist_ok=True)"
      ],
      "metadata": {
        "id": "7xvCs5-Id0Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 蒐集 tail instances\n",
        "TAIL_IDS = [1,2,3]  # hov/person/motorcycle\n",
        "instances = []\n",
        "def _read_img_hw(p):\n",
        "    im = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "    return (im, im.shape[:2]) if im is not None else (None, None)\n",
        "\n",
        "print(\"Collecting tail instances...\")\n",
        "for lab_p in tqdm(glob.glob(os.path.join(LAB_DIR, \"*.txt\"))):\n",
        "    k = os.path.splitext(os.path.basename(lab_p))[0]\n",
        "    img_p = os.path.join(IMG_DIR, f\"{k}.png\")\n",
        "    im, hw = _read_img_hw(img_p)\n",
        "    if im is None: continue\n",
        "    H, W = hw\n",
        "    with open(lab_p, \"r\") as f:\n",
        "        for line in f:\n",
        "            p=line.strip().split()\n",
        "            if len(p)!=5: continue\n",
        "            c=int(p[0]); cx,cy,ww,hh = map(float, p[1:])\n",
        "            if c not in TAIL_IDS: continue\n",
        "            x = int((cx - ww/2)*W); y = int((cy - hh/2)*H)\n",
        "            w = max(1, int(ww*W)); h = max(1, int(hh*H))\n",
        "            x = np.clip(x, 0, max(0,W-1)); y = np.clip(y, 0, max(0,H-1))\n",
        "            if x+w>W: w = W-x\n",
        "            if y+h>H: h = H-y\n",
        "            if w<4 or h<4: continue\n",
        "            crop = im[y:y+h, x:x+w].copy()\n",
        "            if crop.size>0: instances.append((c, crop))\n",
        "print(\"Tail instances collected:\", len(instances))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvqxO79d9lY",
        "outputId": "59b30bf1-0b1e-4646-916f-24f77be9fe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tail instances...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 950/950 [00:46<00:00, 20.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tail instances collected: 9971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _ok_place(px, py, nw, nh, W, H):\n",
        "    if py < int(0.35*H) or (py+nh) > int(0.95*H):\n",
        "        return False\n",
        "    if px < 2 or py < 2 or (px+nw) > (W-2) or (py+nh) > (H-2):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def _iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
        "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)\n",
        "    inter = iw * ih\n",
        "    if inter <= 0: return 0.0\n",
        "    area_a = max(0, ax2-ax1) * max(0, ay2-ay1)\n",
        "    area_b = max(0, bx2-ax1) * max(0, by2-ay1)\n",
        "    return inter / (area_a + area_b - inter + 1e-9)\n",
        "\n",
        "def _boxes_from_lab(lab_path, W, H):\n",
        "    boxes=[]\n",
        "    if os.path.isfile(lab_path):\n",
        "        with open(lab_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                p=line.strip().split()\n",
        "                if len(p)!=5: continue\n",
        "                c=int(p[0]); cx,cy,ww,hh = map(float, p[1:])\n",
        "                x1 = (cx - ww/2)*W; y1 = (cy - hh/2)*H\n",
        "                x2 = (cx + ww/2)*W; y2 = (cy + hh/2)*H\n",
        "                boxes.append([c, x1,y1,x2,y2])\n",
        "    return boxes\n",
        "\n",
        "def _random_light_jitter(img):\n",
        "    img = img.astype(np.float32)\n",
        "    alpha = np.random.uniform(0.9, 1.1)\n",
        "    beta  = np.random.uniform(-8, 8)\n",
        "    out = np.clip(img*alpha + beta, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "def _random_motion_blur(img, k=3):\n",
        "    if random.random()<0.5: return img\n",
        "    kernel = np.zeros((k,k), dtype=np.float32)\n",
        "    if random.random()<0.5: kernel[k//2, :] = 1.0\n",
        "    else: kernel[:, k//2] = 1.0\n",
        "    kernel /= kernel.sum()\n",
        "    return cv2.filter2D(img, -1, kernel)"
      ],
      "metadata": {
        "id": "rTaa86_Id9n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUG_PER_IMAGE_BASE = 1\n",
        "AUG_PER_IMAGE_IF_NO_TAIL = 2\n",
        "PERSON_SMALL_SCALE = (0.5, 0.9)\n",
        "OTHERS_SCALE       = (0.7, 1.1)\n",
        "IOU_BLOCK_THR = 0.3"
      ],
      "metadata": {
        "id": "2n3g-RZkd9qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fi, fold in enumerate(folds):\n",
        "    fold_root = os.path.join(AUG_ROOT, f\"f{fi}\")\n",
        "    IMG_OUT = os.path.join(fold_root, \"images\")\n",
        "    LAB_OUT = os.path.join(fold_root, \"labels\")\n",
        "    os.makedirs(IMG_OUT, exist_ok=True); os.makedirs(LAB_OUT, exist_ok=True)\n",
        "\n",
        "    train_keys = set(fold[\"train\"])\n",
        "    train_imgs = [os.path.join(IMG_DIR, f\"{k}.png\") for k in train_keys if os.path.isfile(os.path.join(IMG_DIR, f\"{k}.png\"))]\n",
        "    print(f\"\\n[Fold {fi}] train images for AUG:\", len(train_imgs))\n",
        "\n",
        "    aug_cnt = 0\n",
        "    for img_p in tqdm(train_imgs, desc=f\"Fold{fi} AUG\"):\n",
        "        k = os.path.splitext(os.path.basename(img_p))[0]\n",
        "        lab_p = os.path.join(LAB_DIR, f\"{k}.txt\")\n",
        "        bg = cv2.imread(img_p, cv2.IMREAD_COLOR)\n",
        "        if bg is None: continue\n",
        "        H, W = bg.shape[:2]\n",
        "        boxes = _boxes_from_lab(lab_p, W, H)\n",
        "        vec = presence_vector.get(k, [0]*len(CLASSES))\n",
        "        n_add = AUG_PER_IMAGE_IF_NO_TAIL if ((vec[1]==0) or (vec[2]==0) or (vec[3]==0)) else AUG_PER_IMAGE_BASE\n",
        "\n",
        "        pasted_xyxy=[]; pasted_yolo=[]\n",
        "        for _ in range(n_add):\n",
        "            if not instances: break\n",
        "            c, crop = random.choice(instances)\n",
        "            scale_min, scale_max = PERSON_SMALL_SCALE if c==2 else OTHERS_SCALE\n",
        "            scale = np.random.uniform(scale_min, scale_max)\n",
        "            nh, nw = max(4, int(crop.shape[0]*scale)), max(4, int(crop.shape[1]*scale))\n",
        "            patch = cv2.resize(crop, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
        "            patch = _random_light_jitter(_random_motion_blur(patch, k=3))\n",
        "            ok=False\n",
        "            for _try in range(10):\n",
        "                px = random.randint(0, max(1, W - nw)); py = random.randint(0, max(1, H - nh))\n",
        "                if not _ok_place(px, py, nw, nh, W, H): continue\n",
        "                x1,y1,x2,y2 = px,py, px+nw, py+nh\n",
        "                bad=False\n",
        "                for _, bx1,by1,bx2,by2 in boxes:\n",
        "                    if _iou_xyxy([x1,y1,x2,y2],[bx1,by1,bx2,by2])>IOU_BLOCK_THR: bad=True; break\n",
        "                if bad: continue\n",
        "                for bx1,by1,bx2,by2 in pasted_xyxy:\n",
        "                    if _iou_xyxy([x1,y1,x2,y2],[bx1,by1,bx2,by2])>IOU_BLOCK_THR: bad=True; break\n",
        "                if bad: continue\n",
        "                ok=True; break\n",
        "            if not ok: continue\n",
        "            bg[py:py+nh, px:px+nw] = patch\n",
        "            pasted_xyxy.append([x1,y1,x2,y2])\n",
        "            cx = (x1+x2)/2.0/W; cy=(y1+y2)/2.0/H; ww=(x2-x1)/W; hh=(y2-y1)/H\n",
        "            pasted_yolo.append([c, cx, cy, ww, hh])\n",
        "\n",
        "        if not pasted_yolo: continue\n",
        "        new_key = f\"{k}_aug_f{fi}\"\n",
        "        out_img = os.path.join(IMG_OUT, f\"{new_key}.png\")\n",
        "        out_lab = os.path.join(LAB_OUT, f\"{new_key}.txt\")\n",
        "        cv2.imwrite(out_img, bg)\n",
        "\n",
        "        yolo_boxes = []\n",
        "        if os.path.isfile(lab_p):\n",
        "            with open(lab_p, \"r\") as f:\n",
        "                for line in f:\n",
        "                    line=line.strip()\n",
        "                    if not line: continue\n",
        "                    yolo_boxes.append(line)\n",
        "        for c,cx,cy,ww,hh in pasted_yolo:\n",
        "            yolo_boxes.append(f\"{c} {cx:.6f} {cy:.6f} {ww:.6f} {hh:.6f}\")\n",
        "        with open(out_lab, \"w\") as f:\n",
        "            f.write(\"\\n\".join(yolo_boxes))\n",
        "        aug_cnt += 1\n",
        "    print(f\"[Fold {fi}] augmented images:\", aug_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVLqdsuud9sd",
        "outputId": "2bbdae3e-77be-4f4e-e45b-6bcd5b9ed368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Fold 0] train images for AUG: 696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold0 AUG: 100%|██████████| 696/696 [01:50<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0] augmented images: 696\n",
            "\n",
            "[Fold 1] train images for AUG: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold1 AUG: 100%|██████████| 700/700 [01:50<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] augmented images: 700\n",
            "\n",
            "[Fold 2] train images for AUG: 697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold2 AUG: 100%|██████████| 697/697 [01:50<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] augmented images: 697\n",
            "\n",
            "[Fold 3] train images for AUG: 691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold3 AUG: 100%|██████████| 691/691 [01:50<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3] augmented images: 691\n",
            "\n",
            "[Fold 4] train images for AUG: 697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold4 AUG: 100%|██████████| 697/697 [01:52<00:00,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4] augmented images: 697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 重寫 train_final/val_final（每折只加本折的 AUG）\n",
        "for fi, fold in enumerate(folds):\n",
        "    base_rfs = os.path.join(LIST_DIR, f\"fold{fi}_train_rfs.txt\")\n",
        "    val_txt  = os.path.join(LIST_DIR, f\"fold{fi}_val.txt\")\n",
        "    with open(base_rfs) as f:\n",
        "        rfs_paths = [ln.strip() for ln in f if ln.strip()]\n",
        "    aug_paths = sorted(glob.glob(os.path.join(AUG_ROOT, f\"f{fi}\", \"images\", \"*.png\")))\n",
        "    train_final = os.path.join(LIST_DIR, f\"fold{fi}_train_final.txt\")\n",
        "    val_final   = os.path.join(LIST_DIR, f\"fold{fi}_val_final.txt\")\n",
        "    with open(train_final, \"w\") as f:\n",
        "        for p in rfs_paths: f.write(p+\"\\n\")\n",
        "        for p in aug_paths: f.write(p+\"\\n\")\n",
        "    with open(val_final, \"w\") as f:\n",
        "        with open(val_txt) as vf:\n",
        "            for ln in vf:\n",
        "                if ln.strip(): f.write(ln)\n",
        "    print(f\"[Fold {fi}] train_final: {len(rfs_paths)} + aug {len(aug_paths)} = {len(rfs_paths)+len(aug_paths)}\")\n",
        "print(\"✅ per-fold AUG 完成（無洩漏）\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvBQZI27d9uw",
        "outputId": "1130f640-36bf-4669-fad9-960a0b58a887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0] train_final: 696 + aug 696 = 1392\n",
            "[Fold 1] train_final: 700 + aug 700 = 1400\n",
            "[Fold 2] train_final: 697 + aug 697 = 1394\n",
            "[Fold 3] train_final: 691 + aug 691 = 1382\n",
            "[Fold 4] train_final: 697 + aug 697 = 1394\n",
            "✅ per-fold AUG 完成（無洩漏）\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RT-DETR 用 data.yaml"
      ],
      "metadata": {
        "id": "wOIpMdiKeGzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YAML_DIR = os.path.join(YOLO_ROOT, \"yamls\")\n",
        "os.makedirs(YAML_DIR, exist_ok=True)\n",
        "for fi in range(5):\n",
        "    yaml_path = os.path.join(YAML_DIR, f\"fold{fi}.yaml\")\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        f.write(f\"\"\"# auto-generated data.yaml for fold {fi}\n",
        "path: {YOLO_ROOT}\n",
        "train: {os.path.join(YOLO_ROOT, \"splits\", f\"fold{fi}_train_final.txt\")}\n",
        "val: {os.path.join(YOLO_ROOT, \"splits\", f\"fold{fi}_val_final.txt\")}\n",
        "nc: 4\n",
        "names: [\"car\",\"hov\",\"person\",\"motorcycle\"]\n",
        "\"\"\")\n",
        "print(\"Wrote YOLO/RT-DETR data yamls under:\", YAML_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U_waPIpd9xF",
        "outputId": "2362efe1-8084-4166-b6cd-52243397f4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote YOLO/RT-DETR data yamls under: /content/yolo_dataset/yamls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics==8.3.204"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ_ohVVPeKxe",
        "outputId": "521c5dc2-5bb8-44df-ce61-87e63a6c0510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO, RTDETR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeiCDg9ld9zk",
        "outputId": "81f997db-4df6-4623-ca30-6d8b01c12a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 先只訓練一折\n",
        "FOLD_TO_RUN = 0\n",
        "DEVICE = 0\n",
        "\n",
        "# VRAM 安全參數\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "try: torch.set_float32_matmul_precision('high')\n",
        "except: pass\n",
        "try: torch.cuda.set_per_process_memory_fraction(0.90, device=DEVICE)\n",
        "except: pass\n",
        "\n",
        "IMG_SZ = 768\n",
        "BATCH  = 8\n",
        "EPOCHS = 150\n",
        "LR0    = 1e-3\n",
        "WD     = 5e-4\n",
        "\n",
        "PROJECT = \"/content/runs_rtdetr_onefold\"\n",
        "os.makedirs(PROJECT, exist_ok=True)\n",
        "run_name = f\"rtdetr_l_f{FOLD_TO_RUN}_{int(time.time())}\"\n"
      ],
      "metadata": {
        "id": "lSYisaXud91b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用前面建立好的 data.yaml\n",
        "assert 'YAML_DIR' in globals(), \"請先執行前面的資料準備，建立 YAML_DIR\"\n",
        "rtd_yaml = os.path.join(YAML_DIR, f\"fold{FOLD_TO_RUN}.yaml\")\n"
      ],
      "metadata": {
        "id": "aj83ZcWkkUfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n========== 🚀 RT-DETR-L Fold {FOLD_TO_RUN} 訓練開始：{run_name} ==========\")\n",
        "model = RTDETR('rtdetr-l.pt')\n",
        "\n",
        "model.train(\n",
        "    data=rtd_yaml,\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMG_SZ,\n",
        "    device=DEVICE,\n",
        "    batch=BATCH,\n",
        "    workers=2,\n",
        "    optimizer='AdamW',\n",
        "    lr0=LR0,\n",
        "    weight_decay=WD,\n",
        "\n",
        "    # 小物/長尾友善增強\n",
        "    mosaic=0.30,\n",
        "    mixup=0.05,\n",
        "    copy_paste=0.20,\n",
        "    hsv_s=0.40,\n",
        "    degrees=5.0,\n",
        "    scale=0.10,\n",
        "    translate=0.05,\n",
        "    shear=0.0,\n",
        "\n",
        "    # 其它通用訓練參數\n",
        "    rect=False,\n",
        "    close_mosaic=20,\n",
        "    cos_lr=True,\n",
        "    patience=25,\n",
        "    amp=True,              # 自動混合精度省顯存\n",
        "\n",
        "    # 從零初始化!!\n",
        "    pretrained=False,\n",
        "\n",
        "    project=PROJECT,\n",
        "    name=run_name,\n",
        "    verbose=True,\n",
        "    save_period=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QfRcCXDeQYt",
        "outputId": "d06b97d0-02e3-4a9e-c4d5-12b703f721f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== 🚀 RT-DETR-L Fold 0 訓練開始：rtdetr_l_f0_1761466324 ==========\n",
            "New https://pypi.org/project/ultralytics/8.3.221 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=20, cls=0.5, compile=False, conf=None, copy_paste=0.2, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/yolo_dataset/yamls/fold0.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.4, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.05, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=0.3, multi_scale=False, name=rtdetr_l_f0_1761466324, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=False, profile=False, project=/content/runs_rtdetr_onefold, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 4.6MB/s 0.2s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "WARNING ⚠️ no model scale passed. Assuming scale='l'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
            "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
            "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
            "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
            "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
            "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
            "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
            "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
            "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
            "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
            " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
            " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
            " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
            " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
            " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
            " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
            " 28        [21, 24, 27]  1   7310072  ultralytics.nn.modules.head.RTDETRDecoder    [4, [256, 256, 256]]          \n",
            "rt-detr-l summary: 457 layers, 32,814,296 parameters, 32,814,296 gradients, 108.0 GFLOPs\n",
            "\n",
            "Transferred 926/941 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 21.2MB/s 0.3s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3545.7±1837.3 MB/s, size: 3971.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels... 1392 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1392/1392 57.1it/s 24.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2516.6±2175.5 MB/s, size: 4255.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels... 190 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 190/190 52.1it/s 3.6s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/labels.cache\n",
            "Plotting labels to /content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
            "Image sizes 768 train, 768 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      1/150      1.28G      2.299      1.713      2.137        346        768: 0% ──────────── 0/174  22.5s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      1/150      9.56G      1.791     0.3541     0.4304        250        768: 100% ━━━━━━━━━━━━ 174/174 1.1it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 0.9it/s 14.0s\n",
            "                   all        190       6429     0.0305      0.139     0.0348    0.00907\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      2/150        11G      1.336     0.4898     0.1939        410        768: 100% ━━━━━━━━━━━━ 174/174 1.3it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 4.9s\n",
            "                   all        190       6429      0.539      0.187     0.0567     0.0199\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      3/150      11.9G      1.021     0.6548      0.117        287        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      3/150      13.2G      1.075     0.5801     0.1305        256        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.327       0.28     0.0805     0.0226\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      4/150        13G     0.9154     0.6339     0.1048        291        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 4.9s\n",
            "                   all        190       6429      0.365       0.34      0.113     0.0393\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      5/150      12.2G      0.899     0.6262      0.123        330        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      5/150      13.2G     0.8554     0.6578    0.09305        260        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.362      0.418      0.127     0.0438\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      6/150      12.4G     0.8849     0.6184      0.109        316        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      6/150      13.2G      0.812     0.6491    0.08459        403        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.171      0.511      0.164       0.06\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      7/150        12G     0.6474     0.6945    0.06087        290        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      7/150      12.9G     0.7939     0.6369    0.07977        235        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.176      0.529      0.183     0.0637\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      8/150      12.9G     0.7792     0.6477    0.07705        314        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.165      0.534       0.22     0.0792\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K      9/150      11.9G     0.7962     0.6399     0.0718        261        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K      9/150      13.2G     0.7631     0.6419     0.0754        297        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.214      0.483      0.212     0.0727\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     10/150      12.2G     0.6565     0.6767    0.07127        405        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     10/150        13G     0.7667     0.6342    0.07457        386        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.192      0.475      0.191     0.0677\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     11/150      12.1G     0.6865      0.669    0.06881        275        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     11/150      13.2G      0.761     0.6436    0.07364        462        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.201      0.563      0.238     0.0906\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     12/150      13.1G     0.7375     0.6352    0.07069        334        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.23      0.513      0.236     0.0843\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     13/150        12G     0.6894     0.6513    0.06203        207        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     13/150      12.8G     0.7352     0.6132    0.06867        461        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.276      0.538      0.291      0.102\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     14/150        12G     0.6302     0.6311    0.05659        320        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     14/150      13.2G     0.7207     0.6093    0.06764        179        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.254      0.584      0.307      0.109\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     15/150      12.8G     0.7429      0.574     0.0893        396        768: 0% ──────────── 0/174  0.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     15/150      13.2G     0.7499     0.5921    0.07151        318        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.329      0.587      0.347      0.117\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     16/150      13.1G     0.7448     0.5801    0.06945        384        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.311      0.532      0.313     0.0982\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     17/150      12.8G      0.861     0.5956    0.09681        398        768: 0% ──────────── 0/174  0.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     17/150        13G     0.7451     0.5832    0.06818        268        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.443      0.579      0.446       0.16\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     18/150      12.1G     0.7322     0.5366    0.06253        300        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     18/150      13.2G     0.7554     0.5424    0.07111        303        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.448      0.554       0.45      0.157\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     19/150      11.9G     0.6392     0.5533     0.0728        222        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     19/150      12.8G      0.797     0.5694    0.07815        246        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.364       0.47      0.343      0.119\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     20/150      13.1G     0.8089     0.5313    0.08263        381        768: 100% ━━━━━━━━━━━━ 174/174 1.3it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.42      0.498      0.429      0.144\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     21/150      12.2G     0.6885       0.53    0.06126        300        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     21/150      13.1G     0.7838     0.5432     0.0761        235        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.421       0.47      0.396      0.138\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     22/150        12G     0.7126     0.6045    0.06808        321        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     22/150      13.2G     0.8163     0.5305    0.08032        224        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.407       0.58      0.443      0.153\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     23/150        12G     0.7763     0.5007    0.06127        331        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     23/150      12.9G     0.7729     0.5105    0.07338        206        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.532      0.502      0.481      0.167\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     24/150      13.2G     0.7596     0.5058    0.07189        183        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.526      0.472      0.487       0.17\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     25/150      12.5G     0.8571     0.4893    0.09505        413        768: 0% ──────────── 0/174  0.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     25/150        13G     0.7649     0.5391     0.0731        298        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.309      0.548      0.336      0.115\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     26/150      12.1G     0.7045     0.6522    0.06916        293        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     26/150      13.1G      0.761     0.5662      0.073        281        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.44      0.544      0.425      0.153\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     27/150      11.9G     0.7346     0.5308    0.07831        164        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     27/150      13.2G     0.7699     0.5521    0.07367        188        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.44      0.559      0.426      0.153\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     28/150      13.2G     0.7595     0.5363    0.07066        289        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.499      0.532      0.483      0.161\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     29/150      12.7G       1.03     0.4434     0.1197        229        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     29/150      13.2G     0.7988     0.5042    0.07767        200        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.389      0.525      0.381      0.127\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     30/150      11.8G     0.5776     0.5754    0.06925        219        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     30/150        13G     0.8057     0.5251    0.08089        292        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.517       0.54       0.48      0.174\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     31/150      12.1G     0.7751     0.5245    0.06628        347        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     31/150      13.2G     0.7613     0.5054    0.07147        356        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.536      0.558       0.53      0.184\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     32/150      13.2G     0.7854     0.5117    0.07471        363        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.432      0.582       0.42      0.151\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     33/150      12.4G     0.7552     0.5524    0.08468        298        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     33/150      13.1G     0.7743     0.5265    0.07584        328        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.394      0.495      0.372      0.126\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     34/150      12.2G     0.7568     0.5326    0.07664        394        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     34/150      13.2G     0.8503     0.5113    0.08851        275        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.473      0.506      0.453      0.149\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     35/150      12.1G     0.8225     0.5313    0.08288        229        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     35/150      13.1G     0.7923     0.5302    0.07816        267        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 4.9s\n",
            "                   all        190       6429      0.329      0.561      0.314      0.112\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     36/150      12.6G     0.7546     0.5821    0.07406        412        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.348      0.611      0.368       0.13\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     37/150        12G     0.6202     0.5901    0.05679        303        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     37/150      12.9G     0.7558     0.5398     0.0713        358        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.472        0.6       0.47      0.164\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     38/150      12.2G     0.8347     0.5245    0.07353        389        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     38/150        13G     0.7634     0.5275    0.07189        366        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.427      0.593      0.443      0.149\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     39/150      12.1G     0.6743     0.5264    0.05062        304        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     39/150      12.7G     0.7544     0.5231    0.07153        408        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.48      0.607      0.466      0.163\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     40/150      12.7G      0.756     0.5493    0.07283        312        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.344      0.617       0.35      0.131\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     41/150        12G     0.7093     0.5737    0.06117        233        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     41/150        13G      0.747     0.5354    0.06885        159        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 4.9s\n",
            "                   all        190       6429      0.531      0.598      0.501      0.175\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     42/150      12.2G     0.8845     0.4792    0.09737        261        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     42/150      13.2G     0.7512     0.4932    0.06941        318        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.564      0.574      0.551      0.188\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     43/150      11.9G     0.7337     0.4644    0.04815        255        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     43/150      13.2G     0.7458     0.5067    0.06895        307        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.502      0.603      0.505      0.169\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     44/150      13.2G      0.742     0.5114    0.06872        264        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.502      0.611      0.492      0.172\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     45/150        12G     0.7821     0.5161    0.06497        274        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     45/150      13.2G     0.7533      0.499    0.07095        406        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.537      0.597      0.539      0.189\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     46/150        12G     0.6874     0.4807    0.05023        355        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     46/150      13.2G     0.7366     0.4897    0.06841        303        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.536      0.605      0.542      0.189\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     47/150      12.2G     0.7083      0.478    0.06883        386        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     47/150      13.2G     0.7226     0.4834    0.06513        446        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 4.9s\n",
            "                   all        190       6429      0.595      0.646      0.592      0.205\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     48/150      13.2G     0.7222     0.4775    0.06524        287        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.602      0.658      0.612      0.207\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     49/150      12.5G     0.8914     0.4562     0.0952        328        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     49/150      13.2G     0.7196     0.4703    0.06463        193        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.623      0.641      0.622      0.216\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     50/150      12.1G     0.8526     0.4434    0.06874        333        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     50/150        13G      0.715     0.4691    0.06205        250        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.608      0.642      0.609      0.209\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     51/150      12.3G     0.6549     0.5001    0.07353        245        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     51/150      13.1G     0.7205     0.4652     0.0638        270        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.609      0.636      0.622      0.218\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     52/150      12.7G     0.7053     0.4686    0.06131        281        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.642      0.654      0.637      0.222\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     53/150        12G     0.6592     0.4706    0.05098        254        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     53/150      12.8G     0.6983     0.4628    0.06072        305        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.632      0.659      0.631      0.221\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     54/150        12G     0.8571     0.4316    0.08856        328        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     54/150      12.7G     0.7092     0.4609    0.06299        346        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.64      0.662      0.638      0.224\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     55/150      12.1G     0.7778      0.457    0.04654        318        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     55/150      13.1G     0.7057     0.4643    0.06257        411        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.619      0.669      0.624      0.222\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     56/150        13G     0.7039     0.4744    0.06115        215        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.661      0.664      0.638       0.22\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     57/150      12.3G     0.8124     0.4642    0.08326        362        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     57/150      12.9G     0.6973     0.4624    0.06065        324        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.668      0.673      0.664      0.233\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     58/150      12.1G     0.6138     0.4463    0.06092        374        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     58/150        13G     0.6927     0.4665    0.06082        277        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.643       0.66      0.631      0.218\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     59/150        12G     0.6504     0.4763    0.05582        226        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     59/150      12.8G     0.6986     0.4624    0.06139        223        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.643      0.673      0.623      0.211\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     60/150      13.1G     0.7024     0.4649    0.06281        225        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.654      0.671      0.653      0.226\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     61/150      12.1G     0.6265     0.4622    0.05697        195        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     61/150      13.2G     0.6964     0.4602    0.06169        325        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.66      0.664      0.645      0.229\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     62/150        12G     0.6751     0.4699    0.04509        296        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     62/150      12.8G     0.6899     0.4616    0.06012        247        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.65      0.664      0.641      0.222\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     63/150        12G     0.6642      0.453    0.05399        305        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     63/150      13.1G     0.6978     0.4575    0.06093        357        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.664       0.67      0.667      0.233\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     64/150      12.8G     0.6917     0.4578    0.06114        298        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.659      0.682      0.667      0.232\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     65/150      12.2G     0.7061     0.4601    0.05749        374        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     65/150      13.2G     0.6874     0.4589    0.06057        316        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.672       0.65      0.648      0.227\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     66/150      12.9G     0.6542     0.4451    0.04653        350        768: 0% ──────────── 0/174  0.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     66/150      13.1G     0.6895     0.4613    0.06098        318        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.625      0.676      0.633      0.218\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     67/150      12.1G     0.7289     0.4494    0.04828        221        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     67/150      12.8G     0.6872     0.4577    0.05906        490        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.643      0.661      0.642      0.221\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     68/150      12.8G      0.681      0.459    0.05805        215        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.669      0.672      0.645      0.222\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     69/150      12.1G     0.7257     0.4502    0.04279        289        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     69/150      13.1G     0.6849     0.4566    0.05953        295        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.658      0.674      0.645      0.221\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     70/150      12.2G     0.6602     0.4565    0.05371        384        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     70/150      13.2G     0.6823      0.459    0.05889        337        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.667      0.662      0.647      0.224\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     71/150        12G     0.5728     0.4637    0.05055        260        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     71/150      12.9G     0.6711     0.4542    0.05757        327        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.674      0.675      0.662      0.231\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     72/150        13G     0.6657     0.4535    0.05767        488        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.647      0.697      0.655      0.223\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     73/150      12.1G     0.6431     0.4639    0.05423        328        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     73/150      13.2G     0.6752     0.4518    0.05977        195        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.657      0.702      0.659      0.227\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     74/150      12.1G     0.6286     0.4541    0.04876        271        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     74/150        13G     0.6679      0.453    0.05689        350        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.681      0.674      0.656      0.219\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     75/150        12G     0.5753     0.4487    0.05004        299        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     75/150      12.6G       0.66     0.4514    0.05631        330        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429       0.68      0.674      0.661       0.23\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     76/150      13.2G     0.6591     0.4513    0.05636        334        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.686      0.683      0.665      0.226\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     77/150        12G     0.5854     0.4501    0.04505        308        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     77/150      13.2G     0.6689     0.4482    0.05791        231        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.689      0.683      0.667      0.226\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     78/150      11.9G      0.619     0.4286    0.04457        188        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     78/150      13.2G     0.6575     0.4504    0.05456        223        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.675       0.67       0.65      0.222\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     79/150      12.8G     0.6901     0.4486    0.06494        482        768: 0% ──────────── 0/174  0.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     79/150      13.1G     0.6482      0.449    0.05434        409        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.688      0.662      0.657      0.221\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     80/150      12.7G     0.6466     0.4517    0.05456        192        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.672      0.684      0.661      0.225\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     81/150      12.2G     0.5214     0.4336    0.04249        341        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     81/150      12.9G     0.6501     0.4491    0.05558        283        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.689       0.68      0.656      0.225\n",
            "\n",
            "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
            "\u001b[K     82/150      12.2G     0.6578     0.4395    0.05354        438        768: 0% ──────────── 0/174  0.7s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     82/150        13G     0.6402     0.4496    0.05381        403        768: 100% ━━━━━━━━━━━━ 174/174 1.4it/s 2:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 2.4it/s 5.0s\n",
            "                   all        190       6429      0.684      0.679      0.661      0.226\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 57, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "82 epochs completed in 3.069 hours.\n",
            "Optimizer stripped from /content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324/weights/last.pt, 66.2MB\n",
            "Optimizer stripped from /content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324/weights/best.pt, 66.2MB\n",
            "\n",
            "Validating /content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324/weights/best.pt...\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "rt-detr-l summary: 302 layers, 31,991,960 parameters, 0 gradients, 103.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 1.6it/s 7.4s\n",
            "                   all        190       6429      0.672      0.672      0.664      0.233\n",
            "                   car        186       4588      0.834      0.877      0.881      0.345\n",
            "                   hov        108        237      0.754      0.829      0.826      0.319\n",
            "                person        100        581      0.517      0.408      0.394      0.104\n",
            "            motorcycle         95       1023      0.581      0.573      0.556      0.164\n",
            "Speed: 0.3ms preprocess, 23.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ef3a81ae330>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0045128,   0.0022564,           0],\n",
              "       [          1,           1,           1, ...,   0.0022594,   0.0011297,           0],\n",
              "       [          1,           1,           1, ...,   0.0002453,  0.00012265,           0],\n",
              "       [          1,           1,           1, ...,  0.00062639,   0.0003132,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.22728,     0.22728,     0.22728, ...,           0,           0,           0],\n",
              "       [    0.15688,     0.15688,     0.15688, ...,           0,           0,           0],\n",
              "       [   0.072333,    0.072333,    0.072333, ...,           0,           0,           0],\n",
              "       [    0.13544,     0.13544,     0.13544, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.12922,     0.12922,     0.12922, ...,           1,           1,           1],\n",
              "       [   0.085714,    0.085714,    0.085714, ...,           1,           1,           1],\n",
              "       [   0.038172,    0.038172,    0.038172, ...,           1,           1,           1],\n",
              "       [   0.074321,    0.074321,    0.074321, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94268,     0.94268,     0.94268, ...,           0,           0,           0],\n",
              "       [    0.92405,     0.92405,     0.92405, ...,           0,           0,           0],\n",
              "       [    0.68847,     0.68847,     0.68847, ...,           0,           0,           0],\n",
              "       [    0.76246,     0.76246,     0.76246, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.23306371067992399)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.34488,     0.31876,     0.10425,     0.16436])\n",
              "names: {0: 'car', 1: 'hov', 2: 'person', 3: 'motorcycle'}\n",
              "nt_per_class: array([4588,  237,  581, 1023])\n",
              "nt_per_image: array([186, 108, 100,  95])\n",
              "results_dict: {'metrics/precision(B)': 0.6717273863276954, 'metrics/recall(B)': 0.6717647819294478, 'metrics/mAP50(B)': 0.6644161032511253, 'metrics/mAP50-95(B)': 0.23306371067992399, 'fitness': 0.23306371067992399}\n",
              "save_dir: PosixPath('/content/runs_rtdetr_onefold/rtdetr_l_f0_1761466324')\n",
              "speed: {'preprocess': 0.32327333155990345, 'inference': 23.24467136841122, 'loss': 0.00053746842145062, 'postprocess': 1.6309253315883228}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_dir = os.path.join(PROJECT, run_name)\n",
        "best_pt = os.path.join(run_dir, \"weights\", \"best.pt\")\n",
        "assert os.path.isfile(best_pt), f\"❌ 未找到 best.pt：{best_pt}\""
      ],
      "metadata": {
        "id": "v_KtHAIieQbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"🔎 驗證 fold{FOLD_TO_RUN}（best.pt）...\")\n",
        "m_best = RTDETR(best_pt)\n",
        "val_res = m_best.val(\n",
        "    data=rtd_yaml,\n",
        "    imgsz=IMG_SZ,\n",
        "    device=DEVICE,\n",
        "    iou=0.5,       # 與 mAP50 對齊\n",
        "    conf=0.001,\n",
        "    split='val',\n",
        "    plots=True\n",
        ")\n",
        "metrics = getattr(val_res, \"results_dict\", {})\n",
        "print(f\"📊 fold{FOLD_TO_RUN} metrics:\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbsxi9l0eQdL",
        "outputId": "b64be3dd-2405-4eb0-a5e6-68a74ab678bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 驗證 fold0（best.pt）...\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "rt-detr-l summary: 302 layers, 31,991,960 parameters, 0 gradients, 103.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 4018.4±125.4 MB/s, size: 4079.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels.cache... 190 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 190/190 383.1Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 0.5it/s 26.3s\n",
            "                   all        190       6429      0.671      0.679       0.67      0.234\n",
            "                   car        186       4588      0.832      0.881      0.882      0.346\n",
            "                   hov        108        237       0.75      0.831      0.836      0.318\n",
            "                person        100        581      0.524      0.428       0.41      0.106\n",
            "            motorcycle         95       1023      0.579      0.577      0.554      0.164\n",
            "Speed: 1.6ms preprocess, 131.5ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "📊 fold0 metrics: {'metrics/precision(B)': 0.6711902585368426, 'metrics/recall(B)': 0.6791064998733918, 'metrics/mAP50(B)': 0.6704319801244922, 'metrics/mAP50-95(B)': 0.2335124578443762, 'fitness': 0.2335124578443762}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 備份到 Drive\n",
        "DRIVE_SAVE_DIR = \"/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/cv_hw2_runs_rtdetr\"\n",
        "os.makedirs(DRIVE_SAVE_DIR, exist_ok=True)\n",
        "drive_best = os.path.join(DRIVE_SAVE_DIR, f\"rtdetr_l_f{FOLD_TO_RUN}_best.pt\")\n",
        "shutil.copy2(best_pt, drive_best)\n",
        "for fn in [\"results.csv\", \"args.yaml\", \"results.png\", \"PR_curve.png\"]:\n",
        "    fp = os.path.join(run_dir, fn)\n",
        "    if os.path.isfile(fp):\n",
        "        shutil.copy2(fp, os.path.join(DRIVE_SAVE_DIR, f\"rtdetr_l_f{FOLD_TO_RUN}_{fn}\"))\n",
        "print(\"✅ 已備份到 Drive：\", drive_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-Uwrj9eQfQ",
        "outputId": "e244d214-b774-4c66-9a16-075e763d753b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 已備份到 Drive： /content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/cv_hw2_runs_rtdetr/rtdetr_l_f0_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推論"
      ],
      "metadata": {
        "id": "8j_epAaJebP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 三折YOLOv8-p +單折RT-DETR-R18 WBF +VAL 掃參數 +TEST\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, csv, cv2, time, json\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DwaU1NCcnmJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHT_DIR    = \"/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/ckpts\"\n",
        "YOLO_WEIGHTS  = [\n",
        "    os.path.join(WEIGHT_DIR, \"best_f0.pt\"),\n",
        "    os.path.join(WEIGHT_DIR, \"best_f1.pt\"),\n",
        "    os.path.join(WEIGHT_DIR, \"best_f2.pt\"),\n",
        "]\n",
        "RTDETR_WEIGHT = os.path.join(WEIGHT_DIR, \"best_rtdetr_f0.pt\")\n",
        "\n",
        "OUT_DIR       = \"/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/submissions\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "K2kghqfxqZOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert \"TEST_DIR\" in globals(), \"請先在上方定義 TEST_DIR = os.path.join(DATASET_ROOT, 'test')\"\n",
        "assert os.path.isdir(TEST_DIR), f\"TEST_DIR 不存在：{TEST_DIR}\"\n"
      ],
      "metadata": {
        "id": "1ZSpDiu1qZQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論/融合參數\n",
        "DEVICE       = 0\n",
        "GLOBAL_IOU   = 0.55\n",
        "SCALES       = [672, 704, 768]\n",
        "HFLIPS       = [False, True]\n",
        "BASE_CONF    = 0.001\n",
        "MAX_DET      = 3000\n",
        "SCORE_POWER  = 1.0\n",
        "WBF_IOU      = 0.50\n",
        "VAR_LAMBDA   = 1.2\n",
        "VAR_SCALE    = 8.0\n",
        "\n",
        "# 類別門檻：car, hov, person, motorcycle\n",
        "PER_CLASS_CONF = {0: 0.34, 1: 0.32, 2: 0.30, 3: 0.30}\n",
        "\n",
        "# 模型校準\n",
        "T_BY_MODEL = {\"yolo\": 1.0, \"rtdetr\": 1.4}\n",
        "B_BY_MODEL_CLASS = {\n",
        "    \"yolo\":   {0:0.0, 1:0.0, 2:0.0, 3:0.0},\n",
        "    \"rtdetr\": {0:-0.05, 1:-0.05, 2:-0.15, 3:-0.10},\n",
        "}\n",
        "W_BY_MODEL_CLASS = {\n",
        "    \"yolo\":   {0:1.0, 1:1.0, 2:1.0, 3:1.0},\n",
        "    \"rtdetr\": {0:0.8, 1:0.7, 2:0.5, 3:0.6},\n",
        "}\n",
        "ASSIST_ONLY_MODELS = {\"rtdetr\"}\n",
        "\n",
        "USE_SOFTNMS   = True\n",
        "SOFTNMS_IOU_P = 0.55\n",
        "SOFTNMS_IOU_O = 0.50\n",
        "SOFTNMS_SIGMA = 0.5\n",
        "SOFTNMS_MIN_S = 0.05\n"
      ],
      "metadata": {
        "id": "eVLGaCRRqZTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 小工具\n",
        "def clipf(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
        "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)\n",
        "    inter = iw * ih\n",
        "    if inter <= 0.0: return 0.0\n",
        "    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)\n",
        "    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)\n",
        "    return inter / (area_a + area_b - inter + 1e-9)\n",
        "\n",
        "def classwise_soft_nms(xyxy_list, score_list, iou_thr, sigma=SOFTNMS_SIGMA, min_score=SOFTNMS_MIN_S):\n",
        "    boxes  = np.array(xyxy_list, float).copy()\n",
        "    scores = np.array(score_list, float).copy()\n",
        "    if boxes.size == 0:\n",
        "        return [], []\n",
        "    keep_boxes, keep_scores = [], []\n",
        "    idxs = np.arange(boxes.shape[0])\n",
        "    while idxs.size > 0:\n",
        "        i = np.argmax(scores[idxs])\n",
        "        sel = idxs[i]\n",
        "        max_box   = boxes[sel].copy()\n",
        "        max_score = float(scores[sel])\n",
        "        keep_boxes.append(max_box.tolist())\n",
        "        keep_scores.append(max_score)\n",
        "\n",
        "        remain = np.delete(idxs, i)\n",
        "        if remain.size == 0: break\n",
        "        ious = np.array([iou_xyxy(max_box, boxes[j]) for j in remain], float)\n",
        "        decay = np.exp(-(ious * ious) / max(1e-9, sigma))\n",
        "        scores[remain] = np.where(ious > iou_thr, scores[remain] * decay, scores[remain])\n",
        "        idxs = remain[scores[remain] >= min_score]\n",
        "    return keep_boxes, keep_scores\n",
        "\n",
        "def wbf_with_model_calibration(\n",
        "    boxes, scores, src_models, src_scales, classes,\n",
        "    iou_thr, score_power, img_w, img_h,\n",
        "    T_by_model, B_by_model_class, W_by_model_class,\n",
        "    agree_gamma_models=0.30, agree_gamma_scales=0.15,\n",
        "    var_lambda=1.2, VAR_SCALE=8.0, assist_only_models=None, eps=1e-6\n",
        "):\n",
        "    \"\"\"\n",
        "    帶模型校準/權重的 WBF + logit 分數融合（保證分數在(0,1)）\n",
        "    - 位置加權: (p_calib ** score_power) * W_{model,class}\n",
        "    - 分數融合: logit(base) + γM*ln(#models) + γS*ln(#scales) - λ*VAR_SCALE*var\n",
        "    - Assist-only: 群組全是 assist 模型則跳過\n",
        "    \"\"\"\n",
        "    if len(boxes)==0: return [], []\n",
        "\n",
        "    # per-box 校準（分數）與位置權重\n",
        "    adj_scores, pos_weights = [], []\n",
        "    for p, m, c in zip(scores, src_models, classes):\n",
        "        p = float(np.clip(p, eps, 1.0 - eps))\n",
        "        Tm = T_by_model.get(m, 1.0)\n",
        "        Bmc= B_by_model_class.get(m, {}).get(c, 0.0)\n",
        "        logit = np.log(p/(1.0 - p))\n",
        "        pm = 1.0 / (1.0 + np.exp(-(logit / Tm + Bmc)))\n",
        "        adj_scores.append(pm)\n",
        "        Wmc= W_by_model_class.get(m, {}).get(c, 1.0)\n",
        "        pos_weights.append((pm ** score_power) * Wmc)\n",
        "\n",
        "    boxes = boxes.copy()\n",
        "    adj_scores = np.array(adj_scores, float)\n",
        "    pos_weights= np.array(pos_weights, float)\n",
        "\n",
        "    used = [False] * len(boxes)\n",
        "    fused_boxes, fused_scores = [], []\n",
        "    order = np.argsort(adj_scores)[::-1]\n",
        "\n",
        "    for i in order:\n",
        "        if used[i]: continue\n",
        "        group = [i]; used[i] = True\n",
        "        base = boxes[i]\n",
        "        # 建群\n",
        "        for j in order:\n",
        "            if used[j]: continue\n",
        "            if iou_xyxy(base, boxes[j]) >= iou_thr:\n",
        "                group.append(j); used[j] = True\n",
        "\n",
        "        g_boxes  = np.array([boxes[k] for k in group], float)\n",
        "        g_p      = adj_scores[group]\n",
        "        g_wpos   = pos_weights[group]\n",
        "        g_models = [src_models[k] for k in group]\n",
        "        g_scales = [src_scales[k] for k in group]\n",
        "\n",
        "        # Assist-only：群組若全是 assist 模型則跳過\n",
        "        if assist_only_models and all([(m in assist_only_models) for m in g_models]):\n",
        "            continue\n",
        "\n",
        "        # 位置融合\n",
        "        w = g_wpos.reshape(-1, 1)\n",
        "        fused = (g_boxes * w).sum(0) / (w.sum(0) + 1e-9)\n",
        "\n",
        "        # 分數融合（logit）\n",
        "        base_score = float(g_p.max())\n",
        "        base_logit = np.log(base_score/(1.0 - base_score))\n",
        "        uniq_models = len(set(g_models))\n",
        "        uniq_scales = len(set(g_scales))\n",
        "        agree_term  = agree_gamma_models * np.log(max(1, uniq_models)) \\\n",
        "                    + agree_gamma_scales * np.log(max(1, uniq_scales))\n",
        "        norm = np.array([img_w, img_h, img_w, img_h], float).reshape(1,4)\n",
        "        var_mean = float(np.var(g_boxes / norm, axis=0).mean())\n",
        "        var_term = var_lambda * VAR_SCALE * var_mean\n",
        "        final_logit = base_logit + agree_term - var_term\n",
        "        final_score = 1.0 / (1.0 + np.exp(-final_logit))  # ∈ (0,1)\n",
        "\n",
        "        fused_boxes.append(fused.tolist())\n",
        "        fused_scores.append(float(final_score))\n",
        "\n",
        "    return fused_boxes, fused_scores"
      ],
      "metadata": {
        "id": "vb3y3_JiqZV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入模型\n",
        "YOLO_WEIGHTS = [w for w in YOLO_WEIGHTS if os.path.isfile(w)]\n",
        "assert YOLO_WEIGHTS, f\"找不到 YOLO 權重：{YOLO_WEIGHTS}\"\n",
        "assert os.path.isfile(RTDETR_WEIGHT), f\"找不到 RT-DETR 權重：{RTDETR_WEIGHT}\"\n",
        "print(\"YOLO 權重：\", YOLO_WEIGHTS)\n",
        "print(\"RT-DETR ：\", RTDETR_WEIGHT)\n",
        "\n",
        "yolo_models  = [YOLO(w) for w in YOLO_WEIGHTS]\n",
        "rtdetr_model = YOLO(RTDETR_WEIGHT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_P33m34qZYm",
        "outputId": "ac6ff2f2-5004-4ba5-ca42-ccad6b3dae56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO 權重： ['/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/ckpts/best_f0.pt', '/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/ckpts/best_f1.pt', '/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/ckpts/best_f2.pt']\n",
            "RT-DETR ： /content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/ckpts/best_rtdetr_f0.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 掃參數\n",
        "\n",
        "# ---- 用 splits 產生 VAL 清單 ----\n",
        "SPLIT_DIR   = \"/content/yolo_dataset/splits\"\n",
        "FOLDS_JSON  = \"/content/reports/folds_5.json\"\n",
        "TRAIN_FOLDS = [0, 1, 2]\n",
        "ALL_FOLDS   = list(range(5))\n",
        "VAL_FOLDS   = [f for f in ALL_FOLDS if f not in TRAIN_FOLDS]\n",
        "\n",
        "def _find_val_list(split_dir, fi):\n",
        "    cand = []\n",
        "    patts = [\n",
        "        f\"val_fold{fi}.txt\", f\"fold{fi}_val.txt\", f\"val_f{fi}.txt\",\n",
        "        f\"fold{fi}.val.txt\", f\"val{fi}.txt\"\n",
        "    ]\n",
        "    for p in patts:\n",
        "        fp = os.path.join(split_dir, p)\n",
        "        if os.path.isfile(fp):\n",
        "            cand.append(fp)\n",
        "    if not cand:\n",
        "        for fp in glob.glob(os.path.join(split_dir, \"*.txt\")):\n",
        "            name = os.path.basename(fp).lower()\n",
        "            if f\"{fi}\" in name and \"val\" in name:\n",
        "                cand.append(fp)\n",
        "    return cand[0] if cand else None\n",
        "\n",
        "def _read_img_label_pairs(list_path):\n",
        "    imgs, labels = [], []\n",
        "    with open(list_path, \"r\") as rf:\n",
        "        for line in rf:\n",
        "            imgp = line.strip()\n",
        "            if not imgp:\n",
        "                continue\n",
        "            if not os.path.isabs(imgp):\n",
        "                imgp = os.path.abspath(imgp)\n",
        "            imgs.append(imgp)\n",
        "            lp = imgp.replace(\"/images/\", \"/labels/\").replace(\"\\\\images\\\\\", \"\\\\labels\\\\\")\n",
        "            lp = os.path.splitext(lp)[0] + \".txt\"\n",
        "            labels.append(lp)\n",
        "    return imgs, labels\n",
        "\n",
        "VAL_IMAGE_LIST, VAL_LABEL_LIST = [], []\n",
        "for fi in VAL_FOLDS:\n",
        "    lst = _find_val_list(SPLIT_DIR, fi)\n",
        "    assert lst is not None, f\"在 {SPLIT_DIR} 找不到 fold {fi} 的 val 清單檔。\"\n",
        "    imgs, labs = _read_img_label_pairs(lst)\n",
        "    VAL_IMAGE_LIST += imgs\n",
        "    VAL_LABEL_LIST += labs\n",
        "\n",
        "print(f\"[VAL] folds = {VAL_FOLDS} → 影像 {len(VAL_IMAGE_LIST)} 張\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaGBl_uoqZa3",
        "outputId": "104f140a-8b10-432a-b19f-958c8ec1b811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] folds = [3, 4] → 影像 382 張\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備VAL 的GT\n",
        "def load_yolo_labels(txt_path, img_w, img_h):\n",
        "    gts = []\n",
        "    if not os.path.isfile(txt_path):\n",
        "        return gts\n",
        "    with open(txt_path, \"r\") as rf:\n",
        "        for line in rf:\n",
        "            ss = line.strip().split()\n",
        "            if len(ss) < 5:\n",
        "                continue\n",
        "            c = int(ss[0]); x=float(ss[1]); y=float(ss[2]); w=float(ss[3]); h=float(ss[4])\n",
        "            x1 = (x - w/2) * img_w; y1 = (y - h/2) * img_h\n",
        "            x2 = (x + w/2) * img_w; y2 = (y + h/2) * img_h\n",
        "            gts.append((c, x1, y1, x2, y2))\n",
        "    return gts\n",
        "\n",
        "gt_by_img = {}\n",
        "val_imgs  = VAL_IMAGE_LIST\n",
        "for imgp, labp in zip(VAL_IMAGE_LIST, VAL_LABEL_LIST):\n",
        "    im = cv2.imread(imgp); H, W = im.shape[:2]\n",
        "    stem = os.path.splitext(os.path.basename(imgp))[0]\n",
        "    gt_by_img[stem] = load_yolo_labels(labp, W, H)"
      ],
      "metadata": {
        "id": "ZBxqSq8hqZdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 簡版AP50計算\n",
        "def compute_ap50(gt_by_img, pred_by_img):\n",
        "    preds = []\n",
        "    for img_id, items in pred_by_img.items():\n",
        "        for c, x1,y1,x2,y2, s in items:\n",
        "            preds.append((s, img_id, c, x1,y1,x2,y2))\n",
        "    preds.sort(key=lambda x: -x[0])\n",
        "\n",
        "    tp = []; fp = []\n",
        "    matched = {img_id: [False]*len(gt_by_img.get(img_id, [])) for img_id in gt_by_img}\n",
        "\n",
        "    def _iou(a, b):\n",
        "        ax1,ay1,ax2,ay2 = a; bx1,by1,bx2,by2 = b\n",
        "        ix1,iy1 = max(ax1,bx1), max(ay1,by1)\n",
        "        ix2,iy2 = min(ax2,bx2), min(ay2,by2)\n",
        "        iw,ih = max(0,ix2-ix1), max(0,iy2-iy1)\n",
        "        inter = iw*ih\n",
        "        if inter<=0: return 0.0\n",
        "        area_a = max(0,ax2-ax1)*max(0,ay2-ay1)\n",
        "        area_b = max(0,bx2-bx1)*max(0,by2-by1)\n",
        "        return inter/(area_a+area_b-inter+1e-9)\n",
        "\n",
        "    GT_POS = sum([len(v) for v in gt_by_img.values()])\n",
        "    for s, img_id, c, x1,y1,x2,y2 in preds:\n",
        "        best_iou = 0.0; best_j = -1\n",
        "        gts = gt_by_img.get(img_id, [])\n",
        "        for j, (gc, gx1,gy1,gx2,gy2) in enumerate(gts):\n",
        "            if gc != c or matched[img_id][j]:\n",
        "                continue\n",
        "            i = _iou((x1,y1,x2,y2), (gx1,gy1,gx2,gy2))\n",
        "            if i > best_iou:\n",
        "                best_iou = i; best_j = j\n",
        "        if best_iou >= 0.5 and best_j >= 0:\n",
        "            matched[img_id][best_j] = True\n",
        "            tp.append(1); fp.append(0)\n",
        "        else:\n",
        "            tp.append(0); fp.append(1)\n",
        "\n",
        "    if not tp:\n",
        "        return 0.0\n",
        "    tp = np.cumsum(tp); fp = np.cumsum(fp)\n",
        "    recall = tp / max(1, GT_POS)\n",
        "    precision = tp / np.maximum(1, tp + fp)\n",
        "    ap = 0.0\n",
        "    for t in np.linspace(0,1,11):\n",
        "        p = precision[recall >= t].max() if np.any(recall >= t) else 0.0\n",
        "        ap += p / 11.0\n",
        "    return float(ap)"
      ],
      "metadata": {
        "id": "EfPcLpM8qZfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 預測\n",
        "def predict_one_image(im_path, params):\n",
        "    im = cv2.imread(im_path); H, W = im.shape[:2]\n",
        "    all_xyxy, all_scores, all_cls = [], [], []\n",
        "    all_models, all_scales = [], []\n",
        "\n",
        "    for sz in params[\"SCALES\"]:\n",
        "        for flip in [False, True]:\n",
        "            im_in = cv2.flip(im, 1) if flip else im\n",
        "            # YOLO\n",
        "            for mdl in params[\"YOLO_MODELS\"]:\n",
        "                r = mdl.predict(source=im_in, imgsz=sz, conf=params[\"BASE_CONF\"], iou=params[\"GLOBAL_IOU\"],\n",
        "                                device=params[\"DEVICE\"], verbose=False, max_det=params[\"MAX_DET\"], augment=False)[0]\n",
        "                if r and r.boxes is not None:\n",
        "                    xyxy = r.boxes.xyxy.cpu().numpy()\n",
        "                    conf = r.boxes.conf.cpu().numpy()\n",
        "                    cls  = r.boxes.cls.cpu().numpy().astype(int)\n",
        "                    if flip and xyxy.size:\n",
        "                        x1 = xyxy[:,0].copy(); x2 = xyxy[:,2].copy()\n",
        "                        xyxy[:,0] = W - x2;    xyxy[:,2] = W - x1\n",
        "                    if xyxy.size:\n",
        "                        all_xyxy.append(xyxy); all_scores.append(conf); all_cls.append(cls)\n",
        "                        all_models.append(np.array([\"yolo\"]*xyxy.shape[0], object))\n",
        "                        all_scales.append(np.array([f\"s{sz}\"]*xyxy.shape[0], object))\n",
        "            # RT-DETR\n",
        "            r = params[\"RT_MODEL\"].predict(source=im_in, imgsz=sz, conf=params[\"BASE_CONF\"], iou=params[\"GLOBAL_IOU\"],\n",
        "                                           device=params[\"DEVICE\"], verbose=False, max_det=params[\"MAX_DET\"], augment=False)[0]\n",
        "            if r and r.boxes is not None:\n",
        "                xyxy = r.boxes.xyxy.cpu().numpy()\n",
        "                conf = r.boxes.conf.cpu().numpy()\n",
        "                cls  = r.boxes.cls.cpu().numpy().astype(int)\n",
        "                if flip and xyxy.size:\n",
        "                    x1 = xyxy[:,0].copy(); x2 = xyxy[:,2].copy()\n",
        "                    xyxy[:,0] = W - x2;    xyxy[:,2] = W - x1\n",
        "                if xyxy.size:\n",
        "                    all_xyxy.append(xyxy); all_scores.append(conf); all_cls.append(cls)\n",
        "                    all_models.append(np.array([\"rtdetr\"]*xyxy.shape[0], object))\n",
        "                    all_scales.append(np.array([f\"s{sz}\"]*xyxy.shape[0], object))\n",
        "\n",
        "    if not all_xyxy:\n",
        "        return []\n",
        "\n",
        "    all_xyxy   = np.concatenate(all_xyxy, axis=0)\n",
        "    all_scores = np.concatenate(all_scores, axis=0)\n",
        "    all_cls    = np.concatenate(all_cls, axis=0)\n",
        "    all_models = np.concatenate(all_models, axis=0)\n",
        "    all_scales = np.concatenate(all_scales, axis=0)\n",
        "\n",
        "    out = []\n",
        "    for c in (0,1,2,3):\n",
        "        idxs = np.where(all_cls == c)[0]\n",
        "        if idxs.size == 0:\n",
        "            continue\n",
        "\n",
        "        b_list = all_xyxy[idxs].tolist()\n",
        "        s_list = all_scores[idxs].tolist()\n",
        "        m_list = all_models[idxs].tolist()\n",
        "        sca_list = all_scales[idxs].tolist()\n",
        "        cls_list = [c] * len(idxs)\n",
        "\n",
        "        group_iou = params[\"WBF_IOU_PERSON\"] if c == 2 else params[\"WBF_IOU\"]\n",
        "        fused_b, fused_s = wbf_with_model_calibration(\n",
        "            b_list, s_list, m_list, sca_list, cls_list,\n",
        "            iou_thr=group_iou, score_power=params[\"SCORE_POWER\"], img_w=W, img_h=H,\n",
        "            T_by_model=params[\"T_BY_MODEL\"], B_by_model_class=params[\"B_BY_MODEL_CLASS\"],\n",
        "            W_by_model_class=params[\"W_BY_MODEL_CLASS\"],\n",
        "            agree_gamma_models=params[\"AGREE_GAMMA_M\"], agree_gamma_scales=params[\"AGREE_GAMMA_S\"],\n",
        "            var_lambda=params[\"VAR_LAMBDA\"], VAR_SCALE=params[\"VAR_SCALE\"],\n",
        "            assist_only_models=params[\"ASSIST_ONLY_MODELS\"]\n",
        "        )\n",
        "\n",
        "        # Soft-NMS\n",
        "        post_iou = params[\"SOFTNMS_IOU_P\"] if c == 2 else params[\"SOFTNMS_IOU_O\"]\n",
        "        if params[\"USE_SOFTNMS\"] and fused_b:\n",
        "            fused_b, fused_s = classwise_soft_nms(fused_b, fused_s, iou_thr=post_iou,\n",
        "                                                  sigma=params[\"SOFTNMS_SIGMA\"], min_score=0.05)\n",
        "        thr = params[\"PER_CLASS_CONF\"].get(c, 0.32)\n",
        "        for bb, sc in zip(fused_b, fused_s):\n",
        "            if sc < thr:\n",
        "                continue\n",
        "            x1,y1,x2,y2 = bb\n",
        "            out.append((c, x1,y1,x2,y2, float(sc)))\n",
        "    return out"
      ],
      "metadata": {
        "id": "PDQn2VhrnmMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 掃描空間\n",
        "param_space = [\n",
        "    {\"T_rtd\":t, \"B_rtd_p\":b, \"W_rtd_p\":w, \"WBF_p\":wbf, \"VL\":vl}\n",
        "    for t   in [1.3, 1.4, 1.5]\n",
        "    for b   in [-0.25, -0.15, -0.10]\n",
        "    for w   in [0.3, 0.5]\n",
        "    for wbf in [0.55, 0.60]\n",
        "    for vl  in [1.0, 1.2]\n",
        "]\n",
        "\n",
        "BASE_PARAMS = {\n",
        "    \"SCALES\": SCALES, \"GLOBAL_IOU\": GLOBAL_IOU, \"BASE_CONF\": BASE_CONF, \"MAX_DET\": MAX_DET,\n",
        "    \"DEVICE\": DEVICE, \"YOLO_MODELS\": yolo_models, \"RT_MODEL\": rtdetr_model,\n",
        "    \"SCORE_POWER\": SCORE_POWER, \"WBF_IOU\": WBF_IOU, \"WBF_IOU_PERSON\": 0.60,\n",
        "    \"AGREE_GAMMA_M\": 0.30, \"AGREE_GAMMA_S\": 0.15, \"VAR_LAMBDA\": VAR_LAMBDA, \"VAR_SCALE\": VAR_SCALE,\n",
        "    \"T_BY_MODEL\": T_BY_MODEL.copy(),\n",
        "    \"B_BY_MODEL_CLASS\": {k:v.copy() for k,v in B_BY_MODEL_CLASS.items()},\n",
        "    \"W_BY_MODEL_CLASS\": {k:v.copy() for k,v in W_BY_MODEL_CLASS.items()},\n",
        "    \"ASSIST_ONLY_MODELS\": ASSIST_ONLY_MODELS.copy(),\n",
        "    \"PER_CLASS_CONF\": PER_CLASS_CONF.copy(),\n",
        "    \"SOFTNMS_IOU_P\": SOFTNMS_IOU_P, \"SOFTNMS_IOU_O\": SOFTNMS_IOU_O,\n",
        "    \"SOFTNMS_SIGMA\": SOFTNMS_SIGMA, \"USE_SOFTNMS\": USE_SOFTNMS,\n",
        "}"
      ],
      "metadata": {
        "id": "lIPO58RvnmOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_subset = val_imgs[:400]  # 加速\n",
        "results = []\n",
        "\n",
        "early_stop_patience = 8\n",
        "best_ap = 0\n",
        "stable_count = 0\n",
        "\n",
        "for i, cfg in enumerate(param_space):\n",
        "    params = BASE_PARAMS.copy()\n",
        "    params[\"T_BY_MODEL\"] = {\"yolo\":1.0, \"rtdetr\":cfg[\"T_rtd\"]}\n",
        "    params[\"B_BY_MODEL_CLASS\"] = {\n",
        "        \"yolo\":   {0:0,1:0,2:0,3:0},\n",
        "        \"rtdetr\": {0:-0.05,1:-0.05,2:cfg[\"B_rtd_p\"],3:-0.10}\n",
        "    }\n",
        "    params[\"W_BY_MODEL_CLASS\"] = {\n",
        "        \"yolo\":   {0:1,1:1,2:1,3:1},\n",
        "        \"rtdetr\": {0:0.8,1:0.7,2:cfg[\"W_rtd_p\"],3:0.6}\n",
        "    }\n",
        "    params[\"WBF_IOU_PERSON\"] = cfg[\"WBF_p\"]\n",
        "    params[\"VAR_LAMBDA\"]     = cfg[\"VL\"]\n",
        "\n",
        "    pred_by_img = {}\n",
        "    for pth in val_subset:\n",
        "        stem = os.path.splitext(os.path.basename(pth))[0]\n",
        "        preds = predict_one_image(pth, params)\n",
        "        pred_by_img[stem] = preds\n",
        "\n",
        "    ap50 = compute_ap50(gt_by_img, pred_by_img)\n",
        "    results.append((ap50, cfg))\n",
        "    print(f\"[VAL] AP50={ap50:.5f} cfg={cfg}\")\n",
        "\n",
        "    if ap50 - best_ap < 0.0005:  # 連續N組差異小於閾值\n",
        "        stable_count += 1\n",
        "    else:\n",
        "        best_ap = ap50\n",
        "        stable_count = 0\n",
        "    if stable_count >= early_stop_patience:\n",
        "        print(f\"🟢 AP50 已收斂，提早停止於第 {i+1}/{len(param_space)} 組。\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "PZPs-gTxnmRH",
        "outputId": "fd15f565-6adc-4791-9d8a-32ec7abedffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] AP50=0.86133 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.3, 'WBF_p': 0.55, 'VL': 1.0}\n",
            "[VAL] AP50=0.86133 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.3, 'WBF_p': 0.55, 'VL': 1.2}\n",
            "[VAL] AP50=0.86124 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.3, 'WBF_p': 0.6, 'VL': 1.0}\n",
            "[VAL] AP50=0.86124 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.3, 'WBF_p': 0.6, 'VL': 1.2}\n",
            "[VAL] AP50=0.86162 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.0}\n",
            "[VAL] AP50=0.86162 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.2}\n",
            "[VAL] AP50=0.86135 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.6, 'VL': 1.0}\n",
            "[VAL] AP50=0.86135 cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.6, 'VL': 1.2}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-459310232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_one_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpred_by_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2112637270.py\u001b[0m in \u001b[0;36mpredict_one_image\u001b[0;34m(im_path, params)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# YOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"YOLO_MODELS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 r = mdl.predict(source=im_in, imgsz=sz, conf=params[\"BASE_CONF\"], iou=params[\"GLOBAL_IOU\"],\n\u001b[0m\u001b[1;32m     13\u001b[0m                                 device=params[\"DEVICE\"], verbose=False, max_det=params[\"MAX_DET\"], augment=False)[0]\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;31m# Postprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_postprocess_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/predict.py\u001b[0m in \u001b[0;36mpostprocess\u001b[0;34m(self, preds, img, orig_imgs, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m     55\u001b[0m         \u001b[0msave_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         preds = nms.non_max_suppression(\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/nms.py\u001b[0m in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, rotated, end2end, return_idxs)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchNMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# limit detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/nms.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# Vectorized IoU calculation for remaining boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mxx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0myy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mxx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "BEST_NOW = sorted(results, key=lambda x: -x[0])[:2]\n",
        "print(BEST_NOW)\n",
        "with open(os.path.join(OUT_DIR, \"best_now_partial.json\"), \"w\") as f:\n",
        "    json.dump({\"best\": [{\"ap50\": ap, \"cfg\": cfg} for ap, cfg in BEST_NOW]}, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pD7bJqEe2B3",
        "outputId": "c24d54e4-90f5-48e9-b3a0-1b8b409ea705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.8616242960530219, {'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.2}), (0.8616228850089256, {'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.0})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 取前 2 名，存 JSON ----\n",
        "results.sort(key=lambda x: -x[0])\n",
        "best2 = results[:2]\n",
        "print(\"Top-2 (AP50 on VAL):\")\n",
        "for ap, cfg in best2:\n",
        "    print(f\"  AP50={ap:.5f}  cfg={cfg}\")\n",
        "\n",
        "BEST_JSON = os.path.join(OUT_DIR, \"best2_configs.json\")\n",
        "with open(BEST_JSON, \"w\") as wf:\n",
        "    json.dump({\"best\": [{\"ap50\": ap, \"cfg\": cfg} for ap, cfg in best2]}, wf, indent=2)\n",
        "print(\"Saved:\", BEST_JSON)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ks_FGk7qxdB",
        "outputId": "f7e9c8e4-1ce8-4820-b1cc-54ea13c058f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-2 (AP50 on VAL):\n",
            "  AP50=0.86162  cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.2}\n",
            "  AP50=0.86162  cfg={'T_rtd': 1.3, 'B_rtd_p': -0.25, 'W_rtd_p': 0.5, 'WBF_p': 0.55, 'VL': 1.0}\n",
            "Saved: /content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/submissions/best2_configs.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(BEST_JSON, \"r\") as rf:\n",
        "    best2 = json.load(rf)[\"best\"]\n",
        "\n",
        "test_imgs = sorted(glob.glob(os.path.join(TEST_DIR, \"*.jpg\")) + glob.glob(os.path.join(TEST_DIR, \"*.png\")))\n",
        "assert test_imgs, f\"在 {TEST_DIR} 找不到測試影像\"\n",
        "\n",
        "for rank, item in enumerate(best2, start=1):\n",
        "    cfg = item[\"cfg\"]\n",
        "    params = BASE_PARAMS.copy()\n",
        "    params[\"T_BY_MODEL\"] = {\"yolo\":1.0, \"rtdetr\":cfg[\"T_rtd\"]}\n",
        "    params[\"B_BY_MODEL_CLASS\"] = {\"yolo\":{0:0,1:0,2:0,3:0}, \"rtdetr\":{0:-0.05,1:-0.05,2:cfg[\"B_rtd_p\"],3:-0.10}}\n",
        "    params[\"W_BY_MODEL_CLASS\"] = {\"yolo\":{0:1,1:1,2:1,3:1}, \"rtdetr\":{0:0.8,1:0.7,2:cfg[\"W_rtd_p\"],3:0.6}}\n",
        "    params[\"WBF_IOU_PERSON\"] = cfg[\"WBF_p\"]\n",
        "    params[\"VAR_LAMBDA\"]     = cfg[\"VL\"]\n",
        "\n",
        "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    csv_path = os.path.join(OUT_DIR, f\"submission_best{rank}_{ts}.csv\")\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f); writer.writerow([\"Image_ID\",\"PredictionString\"])\n",
        "        for i, pth in enumerate(test_imgs, start=1):\n",
        "            preds = predict_one_image(pth, params)  # [(c,x1,y1,x2,y2,score)]\n",
        "            parts = []\n",
        "            im = cv2.imread(pth); H, W = im.shape[:2]\n",
        "            for c, x1,y1,x2,y2, s in preds:\n",
        "                x1 = clipf(float(x1), 0.0, float(W))\n",
        "                y1 = clipf(float(y1), 0.0, float(H))\n",
        "                w  = clipf(float(x2) - x1, 0.0, float(W) - x1)\n",
        "                h  = clipf(float(y2) - y1, 0.0, float(H) - y1)\n",
        "                parts += [f\"{s:.6f}\", f\"{x1:.1f}\", f\"{y1:.1f}\", f\"{w:.1f}\", f\"{h:.1f}\", str(int(c))]\n",
        "            writer.writerow([i, \" \".join(parts)])\n",
        "    print(f\"✅ 輸出提交檔：{csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca7MLcosqxfR",
        "outputId": "3165a2c1-b129-4709-9c44-ef72f6462001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 輸出提交檔：/content/drive/MyDrive/ComputerVision_DL/hw2_longtail_od/submissions/submission_best1_20251028-062229.csv\n"
          ]
        }
      ]
    }
  ]
}